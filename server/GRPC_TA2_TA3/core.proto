syntax = "proto3";
option go_package = "pipeline";

/*
* This interface is based on the unified API proposal available at
* https://datadrivendiscovery.org/wiki/pages/viewpage.action?pageId=4260430, with changes made to
* account for functionality provided by GRPC. The Core API constitutes a threshold capability,
* aimed at satisfying the train/predict/subset tasks.  We use a URI to point to locations on a file system
* (or other data store), allowing TA3 systems to select a data subset prior to submission to TA2, as well
* as provide a means for TA2 systems to write out the results of pipeline train and predict steps.
*/

import "google/protobuf/descriptor.proto";

extend google.protobuf.FileOptions {
    // 54100 is from the range reserved for internal use within individual organizations.
    // If we will make this protocol public, we should obtain globally unique field number from Google.
    string protocol_version = 54100;
}

// Semver-based version string. Use is it to populate version in SessionRequest and SessionResponse messages.
option (protocol_version) = "2017.9.x_pre";

message SessionContext {
    string session_id = 1;
    // ADDITIONAL FUTURE FIELDS
}

enum StatusCode {
    OK = 0;
    CANCELLED = 1;
    SESSION_UNKNOWN = 2;
    SESSION_ENDED = 3;
    SESSION_EXPIRED = 4;
    INVALID_ARGUMENT = 5;
    RESOURCE_EXHAUSTED = 6;
    UNAVAILABLE = 7;
    FAILED_PRECONDITION = 8;
    OUT_OF_RANGE = 9;
    UNIMPLEMENTED = 10;
    INTERNAL = 11;
    ABORTED = 12;
    UNKNOWN = 13;
}

message Status {
    StatusCode code = 1;
    string details = 2;
}

message Response {
    Status status = 1;
}

// in the future we could also pass arguments allowing one to fork an existing session,
// or provide resource limits on a session (asking TA2 system to terminate work if it exceeds a given limit)
message SessionRequest {
    string user_agent = 1;
    string version = 2;
}

message SessionResponse {
    Response response_info = 1;
    string user_agent = 2;
    string version = 3;
    SessionContext context = 4;
}

enum Progress {
    SUBMITTED = 0;
    RUNNING = 1;
    UPDATED = 2;
    COMPLETED = 3;
}

// enums below are based on values taken from the problem annotation schema defined at
// https://datadrivendiscovery.org/wiki/display/gov/Problem+Annotation+Schema
// as of version 2.12

enum TaskType {                          // Top level classification of the problem
    TASK_TYPE_UNDEFINED = 0;             // TaskType not yet declared
    CLASSIFICATION = 1;
    REGRESSION = 2;
    SIMILARITY_MATCHING = 3;
    LINK_PREDICTION = 4;
    VERTEX_NOMINATION = 5;
    COMMUNITY_DETECTION = 6;
    GRAPH_MATCHING = 7;
    TIMESERIES_FORECASTING = 8;
    COLLABORATIVE_FILTERING = 9;
}

enum TaskSubtype {                       // Secondary classification of the problem
    TASK_SUBTYPE_UNDEFINED = 0;          // TaskSubtype not yet declared
    NONE = 1;                            // No secondary task is applicable for this problem
    BINARY = 2;
    MULTICLASS = 3;
    MULTILABEL = 4;
    UNIVARIATE = 5;
    MULTIVARIATE = 6;
    OVERLAPPING = 7;
    NONOVERLAPPING = 8;
}

enum OutputType {                        // Specifies the type of the output that the model is required to produce
    OUTPUT_TYPE_UNDEFINED = 0;           // Output not yet declared
    CLASS_LABEL = 1;
    PROBABILITY = 2;
    REAL = 3;
    NODE_ID = 4;
    VECTOR_CLASS_LABEL = 5;
    VECTOR_STOCHASTIC = 6;
    VECTOR_REAL = 7;
    FILE = 8;
}

enum Metric {                             // The evaluation metric for any potential solution
    METRIC_UNDEFINED = 0;                 // Metric not yet declared
    ACCURACY = 1;                         // sklearn.metrics.accuracy_score
    F1 = 2;                               // sklearn.metrics.f1_score
    F1_MICRO = 3;                         // sklearn.metrics.f1_score(average='micro')
    F1_MACRO = 4;                         // sklearn.metrics.f1_score(average='macro')
    ROC_AUC = 5;                          // sklearn.metrics.roc_auc_score
    ROC_AUC_MICRO = 6;                    // sklearn.metrics.roc_auc_score(average='micro')
    ROC_AUC_MACRO = 7;                    // sklearn.metrics.roc_auc_score(average='macro')
    ROOT_MEAN_SQUARED_ERROR = 8;          // sqrt(sklearn.metrics.mean_squared_error)
    ROOT_MEAN_SQUARED_ERROR_AVG = 9;      // sum(mean_squared_error_list)/len(mean_squared_error_list)
    MEAN_ABSOLUTE_ERROR = 10;             // sklearn.metrics.mean_absolute_error
    R_SQUARED = 11;                       // sklearn.metrics.r2_score
    NORMALIZED_MUTUAL_INFORMATION = 12;
    JACCARD_SIMILARITY_SCORE = 13;
    EXECUTION_TIME = 14;                  // wall clock time to run the pipeline by TA2
}

message Feature {
    string feature_id = 1; // id of feature within dataset
    string data_uri = 2;   // uri of dataset containing feature
}

message PipelineCreateRequest {
    SessionContext context = 1;
    repeated Feature train_features = 2;  // input path of training corpus
    TaskType task = 3;
    TaskSubtype task_subtype = 4;         // can be set to NONE = 1
    string task_description = 5;          // textual description of the task, if available
    OutputType output = 6;
    repeated Metric metrics = 7;          // specify a list of evaluation metrics
    repeated Feature target_features = 8; // specify a list of targets to predict
    int32 max_pipelines = 9;              // maximum number of pipelines to return
}

message Score {
    Metric metric = 1;
    float value = 2;
}

message Pipeline {
    repeated string predict_result_uris = 1;  // output path to predicted results on training data
    OutputType output = 2;
    repeated Score scores = 3;
}

message PipelineCreateResult {
    Response response_info = 1;
    Progress progress_info = 2;
    string pipeline_id = 3;
    // Will be set if progress info value is UPDATED or COMPLETED
    Pipeline pipeline_info = 4;
}

message PipelineExecuteRequest {
    SessionContext context = 1;
    string pipeline_id = 2;
    repeated Feature predict_features = 3;  // input feature data to pass to the pipeline
}

message PipelineExecuteResult {
    Response response_info = 1;
    Progress progress_info = 2;
    string pipeline_id = 3;
    // Will be set if progress info value is UPDATED or COMPLETED
    repeated string result_uris = 4;  // output path to predicted results on eval data
}

message PipelineListRequest {
    SessionContext context = 1;
}

message PipelineListResult {
    Response response_info = 1;
    repeated string pipeline_ids = 2;
}

message PipelineCreateResultsRequest {
    SessionContext context = 1;
    repeated string pipeline_ids = 2;
}

message PipelineExecuteResultsRequest {
    SessionContext context = 1;
    repeated string pipeline_ids = 2;
}

message UpdateProblemSchemaRequest {
    message ReplaceProblemSchemaField {
        oneof update {
            TaskType task_type = 1;
            TaskSubtype task_subtype = 2;
            string task_description = 3;
            OutputType output_type = 4;
            Metric metric = 5;
        }
    }
    repeated ReplaceProblemSchemaField updates = 1;
}

service Core {
    // Train step - multiple result messages returned via GRPC streaming.
    rpc CreatePipelines(PipelineCreateRequest) returns (stream PipelineCreateResult) {}

    // Predict step - multiple results messages returned via GRPC streaming.
    rpc ExecutePipeline(PipelineExecuteRequest) returns (stream PipelineExecuteResult) {}

    // Get pipelines already present in the session.
    rpc ListPipelines(PipelineListRequest) returns (PipelineListResult) {}
    rpc GetCreatePipelineResults(PipelineCreateResultsRequest) returns (stream PipelineCreateResult) {}
    rpc GetExecutePipelineResults(PipelineExecuteResultsRequest) returns (stream PipelineExecuteResult) {}

    // Update problem schema
    rpc UpdateProblemSchema(UpdateProblemSchemaRequest) returns (Response) {}

    // Session management
    rpc StartSession(SessionRequest) returns (SessionResponse) {}
    rpc EndSession(SessionContext) returns (Response) {}
}
